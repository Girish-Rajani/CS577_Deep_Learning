{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eeb9978",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss over epoch: 1.6863\n",
      "Training acc over epoch: 0.4250\n",
      "Validation loss over epoch: 0.7996\n",
      "Validation acc over epoch: 0.2800\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss over epoch: 1.0131\n",
      "Training acc over epoch: 0.3375\n",
      "Validation loss over epoch: 1.1981\n",
      "Validation acc over epoch: 0.4000\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss over epoch: 1.0209\n",
      "Training acc over epoch: 0.4125\n",
      "Validation loss over epoch: 1.0087\n",
      "Validation acc over epoch: 0.2800\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss over epoch: 1.0627\n",
      "Training acc over epoch: 0.3875\n",
      "Validation loss over epoch: 1.0447\n",
      "Validation acc over epoch: 0.3200\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss over epoch: 1.0180\n",
      "Training acc over epoch: 0.4125\n",
      "Validation loss over epoch: 1.0829\n",
      "Validation acc over epoch: 0.6800\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss over epoch: 1.1494\n",
      "Training acc over epoch: 0.4875\n",
      "Validation loss over epoch: 1.0952\n",
      "Validation acc over epoch: 0.6800\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss over epoch: 1.0349\n",
      "Training acc over epoch: 0.6250\n",
      "Validation loss over epoch: 1.0410\n",
      "Validation acc over epoch: 0.6800\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss over epoch: 0.8189\n",
      "Training acc over epoch: 0.6250\n",
      "Validation loss over epoch: 1.0005\n",
      "Validation acc over epoch: 0.6800\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss over epoch: 0.9712\n",
      "Training acc over epoch: 0.7125\n",
      "Validation loss over epoch: 0.9642\n",
      "Validation acc over epoch: 0.6800\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss over epoch: 0.5694\n",
      "Training acc over epoch: 0.6875\n",
      "Validation loss over epoch: 0.9723\n",
      "Validation acc over epoch: 0.9200\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss over epoch: 0.5463\n",
      "Training acc over epoch: 0.7750\n",
      "Validation loss over epoch: 0.7561\n",
      "Validation acc over epoch: 0.6800\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss over epoch: 0.4832\n",
      "Training acc over epoch: 0.7625\n",
      "Validation loss over epoch: 0.6864\n",
      "Validation acc over epoch: 0.8800\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss over epoch: 0.2986\n",
      "Training acc over epoch: 0.8125\n",
      "Validation loss over epoch: 0.6348\n",
      "Validation acc over epoch: 0.6800\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss over epoch: 0.6769\n",
      "Training acc over epoch: 0.8000\n",
      "Validation loss over epoch: 0.6162\n",
      "Validation acc over epoch: 0.9200\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss over epoch: 0.5298\n",
      "Training acc over epoch: 0.8500\n",
      "Validation loss over epoch: 0.5559\n",
      "Validation acc over epoch: 0.8000\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss over epoch: 0.1065\n",
      "Training acc over epoch: 0.8875\n",
      "Validation loss over epoch: 0.5306\n",
      "Validation acc over epoch: 0.6800\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss over epoch: 0.4098\n",
      "Training acc over epoch: 0.9000\n",
      "Validation loss over epoch: 0.4858\n",
      "Validation acc over epoch: 0.9600\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss over epoch: 0.4100\n",
      "Training acc over epoch: 0.9750\n",
      "Validation loss over epoch: 0.3930\n",
      "Validation acc over epoch: 0.9600\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss over epoch: 0.2988\n",
      "Training acc over epoch: 0.9250\n",
      "Validation loss over epoch: 0.4229\n",
      "Validation acc over epoch: 0.8800\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss over epoch: 0.3973\n",
      "Training acc over epoch: 0.8875\n",
      "Validation loss over epoch: 0.3282\n",
      "Validation acc over epoch: 0.9600\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Girish Rajani-Bathija\n",
    "A20503736\n",
    "CS 577 - F22\n",
    "Assignment 2 Part 2 Question 1 - Writing a Training Loop from Scratch\n",
    "'''\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import models, layers\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Load iris dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "def load_iris_data(url):\n",
    "    dataframe = pd.read_csv(url, header=None)\n",
    "    X = dataframe.iloc[:, :-1]\n",
    "    Y = dataframe.iloc[:, -1]\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(X, Y, test_size=0.3)\n",
    "    return train_data, test_data, train_labels, test_labels\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = load_iris_data(url)\n",
    "\n",
    "#normalize training and testing data\n",
    "train_data = preprocessing.normalize(train_data)\n",
    "test_data = preprocessing.normalize(test_data)\n",
    "\n",
    "#encode and vectorize labels using label encoder and categorical encoding\n",
    "lbl_encoder = LabelEncoder()\n",
    "train_labels_encoded = lbl_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = lbl_encoder.fit_transform(test_labels)\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels_encoded)\n",
    "one_hot_test_labels = to_categorical(test_labels_encoded)\n",
    "\n",
    "\n",
    "#Build the network\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='sigmoid', input_shape=(4,)))\n",
    "model.add(layers.Dense(32, activation='sigmoid'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "#try 4,4,3 for units per layer or 32,16,3\n",
    "\n",
    "#Compile the model using optimizer and loss function\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "#Create validation set from training data\n",
    "x_val = train_data[:25]\n",
    "partial_x_train = train_data[25:]\n",
    "y_val = one_hot_train_labels[:25]\n",
    "partial_y_train = one_hot_train_labels[25:]\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "#Prepare training and validation dataset for training loop\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((partial_x_train, partial_y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    #Iterate through batches in the training data\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            #forward pass\n",
    "            logits = model(x_batch_train, training=True)  \n",
    "\n",
    "            #Compute the loss value\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "\n",
    "        #Backpropagation to calculate the gradient\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        #Update weights using gradients derived from backpropagation\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        #Update training metric.\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        \n",
    "    #Print training loss at the end of each epoch\n",
    "    print(\"Training loss over epoch: %.4f\" % (float(loss_value),))        \n",
    "            \n",
    "    # Print training loss at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    #Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        \n",
    "        #Update validation metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    \n",
    "    val_loss_value = loss_fn(y_batch_val, val_logits)\n",
    "    \n",
    "    #Print validation loss and accuracy at the end of each epoch\n",
    "    print(\"Validation loss over epoch: %.4f\" % (float(val_loss_value),))\n",
    "    print(\"Validation acc over epoch: %.4f\" % (float(val_acc),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a7948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
